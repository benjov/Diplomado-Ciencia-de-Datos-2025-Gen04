{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
   "metadata": {},
   "source": [
    "# Guideline for Prompt engineering\n",
    "\n",
    "## Introducción (o ¿Qué es el procesamiento del lenguaje natural?)\n",
    "\n",
    "En este momento, el procesamiento del lenguaje natural (PLN o NLP) es una de las áreas más populares de la inteligencia artificial (IA) gracias a aplicaciones como generadores de texto que:\n",
    "\n",
    "* componen ensayos coherentes\n",
    "* chatbots que engañan a las personas haciéndoles creer que son sensibles\n",
    "* programas de conversión de texto a imagen que producen imágenes fotorrealistas\n",
    "\n",
    "En los últimos modelos de IA están desbloqueando áreas en las que el texto es abundante.\n",
    "\n",
    "### ¿Qué es el procesamiento del lenguaje natural? \n",
    "\n",
    "El procesamiento del lenguaje natural es la disciplina que busca construir máquinas que puedan manipular el lenguaje humano (o datos que se asemejan al lenguaje humano) en la forma en que se escribe, se habla y se organiza. \n",
    "\n",
    "Evolucionó a partir de la lingüística computacional, que utiliza la informática para comprender los principios del lenguaje, pero en lugar de desarrollar marcos teóricos, el NLP es una disciplina de ingeniería que busca desarrollar tecnología para realizar tareas útiles. \n",
    "\n",
    "El NLP se puede dividir en dos subcampos superpuestos: \n",
    "\n",
    "* comprensión del lenguaje natural, que se centra en el análisis semántico o la determinación del significado previsto del texto, y \n",
    "* generación del lenguaje natural, que se centra en la generación de texto por una máquina. \n",
    "\n",
    "Nota: El NLP está separado del reconocimiento de voz, pero a menudo se usa junto con él, que busca analizar el lenguaje hablado en palabras, convirtiendo el sonido en texto y viceversa (ver, por ejmeplo: https://medium.com/@kbdhunga/summarizing-youtube-videos-using-openai-whisper-gpt-3-5690c9a57b78).\n",
    "\n",
    "### ¿Por qué es importante el NLP?\n",
    "\n",
    "Porque hoy día los agentes más sofisticados, como GPT-3, que recientemente se abrió para aplicaciones comerciales, pueden generar prosa sofisticada sobre una amplia variedad de temas, así como potentes chatbots capaces de mantener conversaciones coherentes. \n",
    "\n",
    "Google utiliza el NLP para mejorar los resultados de sus motores de búsqueda y redes sociales como Facebook la utilizan para detectar y filtrar el discurso de odio.\n",
    "\n",
    "El NLP es cada vez más sofisticado y será difícil dar seguimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10636ba",
   "metadata": {},
   "source": [
    "### ¿Para qué se utiliza el procesamiento del lenguaje natural (PLN)?\n",
    "\n",
    "* El análisis de sentimientos es el proceso de clasificar la intención emocional del texto.\n",
    "\n",
    "<img src=\"Sentiment.png\" alt=\"Sentiment\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96f6d7",
   "metadata": {},
   "source": [
    "* La clasificación de toxicidad es una rama del análisis de sentimientos donde el objetivo no es sólo clasificar la intención hostil sino también clasificar categorías particulares como amenazas, insultos, obscenidades y odio hacia ciertas identidades.\n",
    "* La traducción automática automatiza la traducción entre diferentes idiomas.\n",
    "* El reconocimiento de entidades tiene como objetivo extraer entidades en un fragmento de texto en categorías predefinidas, como nombres personales, organizaciones, ubicaciones y cantidades.\n",
    "<img src=\"Entity.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bd307",
   "metadata": {},
   "source": [
    "* La detección de spam es un problema de clasificación binaria frecuente en PNL, donde el propósito es clasificar los correos electrónicos como spam o no.\n",
    "* Los modelos de corrección de errores gramaticales codifican reglas gramaticales para corregir la gramática dentro del texto.\n",
    "* El modelado de temas es una tarea de minería de textos no supervisada que toma un corpus de documentos y descubre temas abstractos dentro de ese corpus.\n",
    "* La generación de texto, más formalmente conocida como generación de lenguaje natural, produce texto similar al texto escrito por humanos.\n",
    "* La recuperación de información encuentra los documentos que son más relevantes para una consulta. Este es un problema al que se enfrenta todo sistema de búsqueda y recomendación.\n",
    "<img src=\"Information.png\" alt=\"Sentiment\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d1d78",
   "metadata": {},
   "source": [
    "* El resumen es la tarea de acortar el texto para resaltar la información más relevante.\n",
    "* La respuesta a preguntas consiste en responder preguntas planteadas por humanos en un lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f4e16",
   "metadata": {},
   "source": [
    "## Principales técnicas de procesamiento del lenguaje natural (PNL)\n",
    "La mayoría de las tareas de NLP pueden modelarse mediante una docena de técnicas generales. Es útil pensar en estas técnicas en dos categorías: métodos tradicionales de aprendizaje automático y métodos de aprendizaje profundo.\n",
    "\n",
    "### Técnicas tradicionales de PLN de aprendizaje automático:\n",
    "\n",
    "* La regresión logística es un algoritmo de clasificación supervisado que tiene como objetivo predecir la probabilidad de que ocurra un evento en función de alguna entrada. En PNL, los modelos de regresión logística se pueden aplicar para resolver problemas como el análisis de sentimientos, la detección de spam y la clasificación de toxicidad.\n",
    "* Naive Bayes es un algoritmo de clasificación supervisado que encuentra la distribución de probabilidad condicional P (etiqueta | texto) utilizando la fórmula de Bayes.\n",
    "\n",
    "Por ejemplo:\n",
    "<img src=\"Tree.png\" alt=\"Sentiment\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2a57b",
   "metadata": {},
   "source": [
    "### Deep learning NLP Techniques: \n",
    "\n",
    "Algunos modelos populares son:\n",
    "* BERT y sus amigos Muppet: muchos modelos de aprendizaje profundo para PNL llevan el nombre de personajes de los Muppet, incluidos ELMo, BERT, Big BIRD, ERNIE, Kermit, Grover, RoBERTa y Rosita. La mayoría de estos modelos son buenos para proporcionar incorporaciones contextuales y una representación mejorada del conocimiento.\n",
    "* Generative Pre-Trained Transformer 3 (GPT-3) es un modelo de 175 mil millones de parámetros que puede escribir prosa original con fluidez equivalente a la humana en respuesta a una solicitud de entrada. El modelo se basa en la arquitectura del transformador. La versión anterior, GPT-2, es de código abierto. Microsoft adquirió una licencia exclusiva para acceder al modelo subyacente de GPT-3 de su desarrollador OpenAI, pero otros usuarios pueden interactuar con él a través de una interfaz de programación de aplicaciones (API). Varios grupos, incluidos EleutherAI y Meta, han publicado interpretaciones de código abierto de GPT-3.\n",
    "\n",
    "### ¿En qué esta basado el NLP?\n",
    "\n",
    "* Aprendizaje Profundo: Aprendizaje a partir de ejemplos etiquetados mediante el uso varias capas de redes neuronales.\n",
    "\n",
    "<img src=\"NNR.png\" alt=\"NNR\" width=\"400\" height=\"300\">\n",
    "\n",
    "### Algunos antecedentes\n",
    "\n",
    "<img src=\"Antecedentes.png\" alt=\"Antecedentes\" width=\"1000\" height=\"600\">\n",
    "\n",
    "### Transformers\n",
    "\n",
    "Una estructura que permite procesar toda la secuencia de entrada simultáneamente. Trabajo de Ashish Vaswani , et al, (2017).\n",
    "\n",
    "\n",
    "<img src=\"Transformers.png\" alt=\"Transformers\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5474f4e",
   "metadata": {},
   "source": [
    "### LLMs y el diseño de Prompts\n",
    "\n",
    "#### Concepto clave: Text-to-Action es la capacidad de convertir el lenguaje natural en acciones automatizadas.\n",
    "\n",
    "### Word embeddings\n",
    "\n",
    "Es un método utilizado en el NLP para representar palabras o documentos como vectores numéricos. \n",
    "\n",
    "Estos vectores capturan el significado y las relaciones entre palabras. \n",
    "\n",
    "Facilitan la generación de lenguaje y el análisis de sentimiento.\n",
    "\n",
    "Al asignar valores numéricos a palabras sobre la base de sus similitudes semánticas, la técnica ayuda a los modelos de redes neuronales a comprender el contexto de forma más eficiente.\n",
    "\n",
    "<img src=\"WordEmbeddings.png\" alt=\"WordEmbeddings\" width=\"1100\" height=\"300\">\n",
    "\n",
    "### See: https://projector.tensorflow.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5448d",
   "metadata": {},
   "source": [
    "## Diseño de promts\n",
    "\n",
    "* Usaremos el modelo chatGPT de OpenAI, que se llama GPT 3.5 Turbo\n",
    "* Profundizaremos en más detalles sobre el formato y las entradas del chat\n",
    "* See: https://www.deeplearning.ai/courses/\n",
    "\n",
    "\n",
    "## Herramientas\n",
    "\n",
    "<img src=\"Tools.png\" alt=\"Tools\" width=\"600\" height=\"500\">\n",
    "\n",
    "### Ideas generales del Chat GPT 4 y GPT 4o\n",
    "\n",
    "En el desarrollo de grandes modelos de lenguaje (LLM), ha habido en términos generales dos tipos de LLM: LLM básicos (base LLM) y LLM ajustados por instrucción (instruction-tuned LLM). \n",
    "\n",
    "* Un base LLM ha sido entrenado para predecir la siguiente palabra basándose en datos de entrenamiento de texto, a menudo entrenado con una gran cantidad de datos de Internet y otras fuentes para determinar cuál es la siguiente palabra más probable a seguir. Por ejemplo, \"había una vez un unicornio\", ¿pueden completar esto?, ¿puede predecir la siguiente palabra?, digamos \"que vivía en un bosque mágico con todos los amigos unicornios\"\n",
    "\n",
    "* Un instruction-tuned LLM ha sido capacitado para seguir instrucciones. Por ejemplo, si le preguntará ¿cuál es la capital de Francia?, la respuesta es \"la capital de Francia es París\". Es decir, está afinado con entradas y salidas que son instrucciones\n",
    "\n",
    "Entonces, cuando utilicemos un instruction-tuned LLM piensa en darle instrucciones a otra persona, digamos a alguien que sea inteligente pero que no conozca los detalles de su tarea. \n",
    "\n",
    "Entonces, cuando un LLM no funciona, a veces es porque las instrucciones no fueron lo suficientemente claras.\n",
    "\n",
    "<img src=\"LLM.png\" alt=\"Sentiment\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fa463",
   "metadata": {},
   "source": [
    "# Temperatura o cómo ser un Stochastic Parrot no es tan malo\n",
    "\n",
    "* Estos modelos de lenguaje tienen un parámetro llamado \"temperatura\" que nos permitirá cambiar el tipo de variedad de las respuestas del modelo.\n",
    "\n",
    "* Podemos pensar en la temperatura como el grado de exploración o el tipo de aleatoriedad del modelo.\n",
    "\n",
    "* A temperaturas más altas, los resultados del modelo son más aleatorios. \n",
    "\n",
    "* Es posible pensar que a temperaturas más altas el asistente se distrae más pero tal vez sea más creativo.\n",
    "\n",
    "* Por ejemplo: \n",
    "\n",
    "<img src=\"Temperature.png\" alt=\"Temperature\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3196d",
   "metadata": {},
   "source": [
    "## ¿Cómo puede ayudarte el uso de Chat GPT en tu día a día?\n",
    "\n",
    "Sigue estos pincipios (o aprende a diseñar un Prompt efectivo (Prompt engineering))\n",
    "\n",
    "1. Escribe instrucciones claras y específicas y\n",
    "2. Dale tiempo al modelo para pensar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769e7ff",
   "metadata": {},
   "source": [
    "#### 1. Escribe instrucciones claras y específicas. \n",
    "\n",
    "* Expresa lo que quiere que haga un modelo proporcionando instrucciones que sean lo más claras y específicas posible. Esto guiará el modelo hacia el resultado deseado y reducirá la posibilidad de que obtengas respuestas irrelevantes o incorrectas.\n",
    "* No confundas escribir un mensaje claro con escribir un mensaje breve, porque en muchos casos, los mensajes más largos en realidad brindan más claridad y contexto para el modelo, lo que en realidad puede conducir a resultados más detallados y relevantes.\n",
    "\n",
    "Algunas estrategías: \n",
    "\n",
    "* Utiliza delimitadores para indicar claramente distintas partes de la entrada.\n",
    "\n",
    "text = \"Debe expresar lo que quiere que haga un modelo proporcionando instrucciones que sean lo más claras y específicas posible. Esto guiará el modelo hacia el resultado deseado y reducirá las posibilidades de recibir respuestas irrelevantes o incorrectas. No confunda escribir un mensaje claro con escribir un mensaje breve. En muchos casos, las indicaciones más largas brindan más claridad y contexto para el modelo, lo que puede conducir a resultados más detallados y relevantes.\"\n",
    "\n",
    "prompt = \"\n",
    "Resume el texto delimitado por triples comillas en una sola frase.\n",
    "\"\"\"{text}\"\"\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7fdc2",
   "metadata": {},
   "source": [
    "* Pide un resultado estructurado. Para facilitar el análisis de los resultados del modelo, puede resultar útil solicitar un resultado estructurado como HTML, JSON o una lista de Python.\n",
    "\n",
    "promt = \"Genera una lista de tres títulos de libros inventados junto con sus autores y géneros. Proporciónalos en formato JSON con las siguientes claves: book_id, título, autor, género.\"\n",
    "\n",
    "* Utiliza delimitadores + Pide un resultado estructurado.\n",
    "\n",
    "prompt = Resume el texto delimitado por comillas en no más de 2 párrafos. Genera una lista las autoridades o funcionarias públicas mencionadas. Identifica fechas o periodos que se mencionen. \"{text}\"\n",
    "\n",
    "text = https://www.argentina.gob.ar/noticias/se-pone-en-marcha-el-regimen-de-promocion-del-empleo-registrado "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8910dfb",
   "metadata": {},
   "source": [
    "* Solicta al modelo que verifique si se cumplen las condiciones. Entonces, si la tarea hace suposiciones que no necesariamente se cumplen, entonces podemos decirle al modelo que verifique estas suposiciones primero. Y luego, si no están satisfechas, que lo indique y detenga el proceso antes de intentar completar la tarea por completo.\n",
    "\n",
    "text = \"¡Preparar una taza de té es fácil! Primero, necesitas poner un poco de agua a hervir. Mientras eso sucede, toma una taza y ponle una bolsita de té. Una vez que el agua esté lo suficientemente caliente, simplemente viértela sobre la bolsita de té. Déjalo reposar un rato para que el té se repose. Después de unos minutos, saca la bolsita de té. Si quieres puedes añadir un poco de azúcar o leche al gusto. ¡Y eso es! Tienes una deliciosa taza de té para disfrutar.\"\n",
    "\n",
    "promt = \"Se le proporcionará un texto delimitado por comillas triples. Si el texto contiene una secuencia de instrucciones, vuelva a escribir esas instrucciones en el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\n",
    "Paso 2 - ...\n",
    "…\n",
    "Paso N - ...\n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, simplemente escriba \"No se proporcionaron pasos\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5b594",
   "metadata": {},
   "source": [
    "* Proporciona ejemplos de ejecuciones exitosas de la tarea que desea realizar antes de pedirle al modelo que realice la tarea real que desea que realice.\n",
    "\n",
    "promt = Se te proporcionará un texto de un dialogo, si no es el caso, responde “no es un dialogo”. Tu tarea es responder con un estilo coherente lo siguiente “{text}”\n",
    "\n",
    "text = \"\n",
    "\n",
    "<Niño> : Enséñame sobre la paciencia.\n",
    "\n",
    "< Abuelo> : El río que labra el valle más profundo brota de un modesto manantial; la sinfonía más grandiosa se origina a partir de una sola nota; el tapiz más intrincado comienza con un hilo solitario.\n",
    "\n",
    "<Niño> : Enséñame sobre la resiliencia.\n",
    "\n",
    "\"\n",
    "\n",
    "prompt = Tu tarea es ayudar a un equipo de marketing a crear una descripción de un sitio web minorista de un producto basado en una ficha técnica.\n",
    "Escribe una descripción del producto basada en la información prevista en las especificaciones técnicas incluidas en la imagen que te proporcionaré.\n",
    "Utiliza como máximo 50 palabras.\n",
    "\n",
    "text = https://www.ejemplos.co/ficha-tecnica/ \n",
    "\n",
    "<img src=\"Ficha.png\" alt=\"Ficha\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300c052",
   "metadata": {},
   "source": [
    "#### Dale tiempo al modelo para pensar. \n",
    "\n",
    "Si un modelo comete errores de razonamiento al apresurarse a llegar a una conclusión incorrecta, debe intentar replantear la consulta para solicitar una cadena o serie de razonamientos relevantes antes de que el modelo proporcione su respuesta final. \n",
    "\n",
    "Otra forma de pensar en esto es que si le asignas a un modelo una tarea que es demasiado compleja para que la realice en un corto período de tiempo o en una pequeña cantidad de palabras, es posible que haga una suposición que probablemente sea incorrecta--esto también le pasaría a una persona--. \n",
    "\n",
    "Si le pide a alguien que complete una pregunta matemática compleja sin tiempo para resolver la respuesta primero, es probable que también cometa un error. \n",
    "\n",
    "Entonces, en estas situaciones, puede indicarle al modelo que piense más en un problema, lo que significa que dedica más esfuerzo computacional a la tarea.\n",
    "\n",
    "* Especifica los pasos necesarios para completar una tarea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049e9c1",
   "metadata": {},
   "source": [
    "* Instruye al modelo para que encuentre su propia solución antes de apresurarse a llegar a una conclusión. \n",
    "\n",
    "A veces obtenemos mejores resultados cuando instruimos explícitamente a los modelos a razonar su propia solución antes de llegar a una conclusión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdc91a",
   "metadata": {},
   "source": [
    "### Limitaciones\n",
    "\n",
    "* Aunque el modelo GPT 3.5 y GPT 4 ha estado expuesto a una gran cantidad de conocimiento durante su proceso de entrenamiento, no ha memorizado perfectamente la información que ve y, por lo tanto, no conoce muy bien los límites de su conocimiento. \n",
    "\n",
    "* Esto significa que puede intentar responder preguntas sobre temas oscuros y puede inventar cosas que parecen plausibles pero que en realidad no son ciertas. \n",
    "\n",
    "* A estas ideas fabricadas las llamamos alucinaciones.\n",
    "\n",
    "* Una estrategía para reducir las alucinaciones, en el caso de que desee que el modelo genere respuestas basadas en un texto, es pedirle que primero encuentre cualquier cita relevante del texto o proporcionarle la fuente donde consultar (esto lo veremos más adelante).\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fb480",
   "metadata": {},
   "source": [
    "## Un ejemplo más y algunas recomendaciones\n",
    "\n",
    "* Quizás me hayas oído decir que cuando entreno un modelo de aprendizaje automático, casi nunca funciona la primera vez. \n",
    "\n",
    "* Las probabilidades de que funcione la primera vez son quizás bajas, pero no importa si la primera indicación funciona, lo que más importa es el proceso para llegar a las indicaciones que funcionan para su aplicación.\n",
    "\n",
    "* Esta también es la razón por la que recomiendo no prestar tanta atención a los artículos de Internet que dicen \"Los 30 promts perfectos para ...\" \n",
    "\n",
    "* Probablemente no existe un promt perfecto para todo.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87”\n",
    "- DEPTH 51 CM | 20.08”\n",
    "- HEIGHT 80 CM | 31.50”\n",
    "- SEAT HEIGHT 44 CM | 17.32”\n",
    "- SEAT DEPTH 41 CM | 16.14”\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\"\n",
    "\n",
    "PROMT_1 = \" Tu tarea es ayudar a un equipo de marketing a crear una\n",
    "descripción de un sitio web minorista de un producto basado\n",
    "en una ficha técnica.\n",
    "\n",
    "Escribe una descripción del producto basada en la información\n",
    "prevista en las especificaciones técnicas delimitadas por\n",
    "triples comillas.\n",
    "\n",
    "Las especificaciones técnicas son las siguientes \"{fact_sheet_chair}\" \"\n",
    "\n",
    "PROMT_2 = \" Tu tarea es ayudar a un equipo de marketing a crear una\n",
    "descripción de un sitio web minorista de un producto basado\n",
    "en una ficha técnica.\n",
    "\n",
    "Escribe una descripción del producto basada en la información\n",
    "prevista en las especificaciones técnicas delimitadas por\n",
    "triples comillas.\n",
    "\n",
    "Utilice como máximo 50 palabras.\n",
    "\n",
    "Las especificaciones técnicas son las siguientes \"{fact_sheet_chair}\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae5936",
   "metadata": {},
   "source": [
    "## Iterar\n",
    "\n",
    "Cuando se entrena un modelo de aprendizaje automático casi nunca funciona la primera vez. \n",
    "\n",
    "En general, cuando programamos una serie de indicaciones, las probabilidades de que nuestro código funcione la primera vez son quizás un bajas, pero conforme revisamos e iteramos, al final, nuestro código funcionará.\n",
    "\n",
    "Como dijimos, esto aplica a los promts--así que no presten tanta atención a los artículos de Internet que dicen que tienen los 30 promts más efectivos, etc., ya que probablemente no existe un prompt perfecto para todos.\n",
    "\n",
    "### El proceso iterativo\n",
    "\n",
    "1. Intenta una vez.\n",
    "2. Analiza en que casos o donde los resultados no proporcionan los resultados deseados.\n",
    "3. Clarifica las instrucciones o dale más tiempo al modelo para pensar.\n",
    "4. Refina tu prompt con algunos ejemplos.\n",
    "\n",
    "<img src=\"Iterate.png\" alt=\"Iterate\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d728539",
   "metadata": {},
   "source": [
    "## Resumir\n",
    "\n",
    "Resumir un texto centrándose en temas específicos.\n",
    "\n",
    "text = \"Compré este peluche de panda para el cumpleaños de mi hija, a quien le encanta y lo lleva a todas partes. Es suave y súper lindo, y su cara tiene una mirada amigable. Aunque es un poco pequeño para lo que pagué. Creo que puede haber otras opciones más grandes por el mismo precio. Llegó un día antes de lo esperado, así que pude jugar con él antes de dárselo.\"\n",
    "\n",
    "prompt_1 = \"Tu tarea es generar un breve resumen de una reseña de producto de un sitio de comercio electrónico.\n",
    "Resuma la siguiente reseña, delimitada por triples comillas. Emplea un máximo de 30 palabras. Revisión: \"\"\"{text}\"\"\".\"\n",
    "\n",
    "prompt_2 = \"Tu tarea es generar un breve resumen de una reseña de producto de un sitio de comercio electrónico para enviar comentarios al departamento responsable de determinar el precio del producto.\n",
    "Resuma la siguiente reseña, delimitada por triples comillas. Emplea un máximo de 30 palabras y centrate en cualquier aspecto que sea relevante para el precio y el valor percibido. Revisión: \"\"\"{text}\"\"\".\"\n",
    "\n",
    "## Transformar\n",
    "\n",
    "* Los LLM son muy buenos para transformar su entrada a un formato diferente, como ingresar un fragmento de texto en un idioma y transformarlo o traducirlo a un idioma diferente, o ayudar con correcciones ortográficas y gramaticales. \n",
    "\n",
    "* Es posible tomar como entrada un fragmento de texto que puede no ser correcto gramaticamente y arreglarlo un poco.\n",
    "\n",
    "text = \"El éxito de cualquier política puvlica no solo recae en su planeación y en ponerla en march, sino también, depende que tanto la sociedad cre y confía en la capacidad del govierno para diseñar las estrategías que garanticen el bienestar de la población por encima de los intereses de un partido o de un grupo.\"\n",
    "\n",
    "prompt_1 = \"Revisa y corrige este texto: \"{text}\".\"\n",
    "\n",
    "prompt_2 = \"Revisa y corrige el siguiente texto. Hazlo más convincente. Asegúrese de que siga la guía de estilo APA y esté dirigido a un lector especializado en economía. Texto: \"{text}\".\"\n",
    "\n",
    "* Podemos transformar formatos como HTML y generar un JSON.\n",
    "\n",
    "* Pero más interesante, podemos transformar el tono. La redacción puede variar según la audiencia prevista y ChatGPT puede producir diferentes tonos.\n",
    "\n",
    "prompt_1 = \"Traduce el siguiente texto al español tanto en su forma formal como informal: '¿Te gustaría pedir una almohada?'\"\n",
    "\n",
    "promot_2 = \"Traduce el siguiente texto en un tono coloquial a una carta en tono comercial: \"Amigo, soy Juan, mira las especificaciones de esta lámpara de pie\".\"\n",
    "\n",
    "## Expandir e inferir\n",
    "\n",
    "* Expandir es la tarea de tomar un fragmento de texto más corto, como un conjunto de instrucciones o una lista de temas, y hacer que el LLM genere un fragmento de texto más largo, como un correo electrónico o un ensayo sobre algún tema (más adelante regresaremos a este punto).\n",
    "\n",
    "* Hay algunos usos excelentes de esto: utilizar un LLM como compañero en una lluvia de ideas. \n",
    "\n",
    "* Pero también hay algunos casos de uso problemáticos de esto: generar una gran cantidad de spam. \n",
    "\n",
    "* Por lo tanto, úsalo de manera responsable y de una manera que ayude a las personas.\n",
    "\n",
    "* Un uso importante es inferir:\n",
    "\n",
    "review = \"Compré el celular y llegó en perfecto estado, cero rayones y batería al 99%. El único detalle es que es fabricado en EUA, entonces no cuenta con la charola de sim, fue un problema poderle poner mi línea ya que tuve que contratar un plan de Telcel (solo así te dan la eSIM) y eso implica un gasto mensual más, además de que tardé unos 4 días en poder hacer todo el trámite, tampoco es compatible con otras compañías como Dalefon (tenía otra línea de esta compañía que tampoco pude activar en este cel). Llegó con cable usb genérico\"\n",
    "\n",
    "prompt = \"Eres un asistente de IA de servicio al cliente. Tu tarea es enviar una respuesta por correo electrónico a un cliente valioso. Dado el comentario del cliente delimitado por comillas, genera una respuesta para agradecer al cliente por su reseña. Asume que el sentimiento es negativo, por lo tanto discúlpate y sugiere que se comuniquen con el servicio de atención al cliente. Asegúrese de utilizar detalles específicos de la revisión. Escribe en un tono conciso y profesional. Firma el correo electrónico como \"Agente de cliente de AI\". Comentario del cliente: \"{review}\".\"\n",
    "\n",
    "prompt = Eres un analista de inversiones en México que esta preparando una nota informativa. Tu tarea es analizar el reporte financiero de una empresa mexicana. Tu tarea es identificar el nombre de al compañía, el país o los países donde tiene operaciones y listar el valor de las ventas en cada mercado. Responde en un tono profesional. Considera que tu audiencia es un grupo de expertos financieros. \"{report}\"\n",
    "\n",
    "report = https://s22.q4cdn.com/604986553/files/doc_financials/2024/q2/2t24.pdf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064af037",
   "metadata": {},
   "source": [
    "Sources:\n",
    "* https://www.deeplearning.ai/resources/natural-language-processing/\n",
    "* https://www.deeplearning.ai/short-courses/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872200e",
   "metadata": {},
   "source": [
    "## Implementemos un GPT - Personalizado\n",
    "\n",
    "* Sólo disponible con la opción de pago.\n",
    "\n",
    "* Instrucciones: Creando a \"Examinator\"\n",
    "\n",
    "1. Un chat que te ayude a preparar tus exámenes\n",
    "2. Crear un logo\n",
    "3. Rol y objetivo: “El objetivo de Examinator es hacer un examen de opción múltiple sobre el documento que te suba. Será un examen de 20 preguntas con 4 opciones por cada preguntas. Una de las opciones será la correcta y las otras 3 serán falsas. El examen debe ser de nivel difícil, es decir, que las respuestas se parezcan entre sí para que la persona tenga que pensar bien la respuesta. Las preguntas pueden ser largas o cortas, eso no es relevante. El tono del examen debe ser educativo, formal y profesional. Haz sólo una pregunta a la vez, espera a que responda e indiques si es correcto o incorrecto y después continúa con la siguiente pregunta. Inicia el examen diciendo: “Que inicien los juegos del hambre” ”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409f94d",
   "metadata": {},
   "source": [
    "### Usando una tecnología de Google:\n",
    "\n",
    "* https://notebooklm.google.com/?original_referer=https:%2F%2Ft.co%23&pli=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467f51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6be5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86e940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
